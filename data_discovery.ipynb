{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"realtime_simulation.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe\n",
    "# Get count of appearances for each customer_id\n",
    "customer_counts = df['customer_id'].value_counts()\n",
    "\n",
    "# Filter for customers appearing once\n",
    "single_transaction_customers = customer_counts[customer_counts == 2]\n",
    "\n",
    "print(f\"Number of customers with single transaction: {len(single_transaction_customers)}\")\n",
    "print(\"\\nThese customers are:\")\n",
    "print(single_transaction_customers)\n",
    "\n",
    "# # If you want to see the actual transactions for these customers:\n",
    "# single_customer_transactions = df[df['customer_id'].isin(single_transaction_customers.index)]\n",
    "# print(\"\\nTheir transactions:\")\n",
    "# print(single_customer_transactions)\n",
    "\n",
    "# As a percentage of total customers\n",
    "total_customers = df['customer_id'].nunique()\n",
    "percentage = (len(single_transaction_customers) / total_customers) * 100\n",
    "print(f\"\\nPercentage of customers with single transaction: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"customer_id\"]==16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(input_file, train_ratio=0.7):\n",
    "    \"\"\"Split input CSV into historical and real-time simulation data\"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['purchase_timestamp'] = pd.to_datetime(df['purchase_timestamp'])  # Ensure timestamp is datetime\n",
    "    train_df, test_df = train_test_split(df, train_size=train_ratio, random_state=42)\n",
    "    \n",
    "    # Save splits to CSV\n",
    "    train_df.to_csv('historical_data.csv', index=False)\n",
    "    test_df.to_csv('realtime_simulation.csv', index=False)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "split_data(input_file=\"data/test_task_data.csv\", train_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "links\n",
    "\n",
    "https://www.youtube.com/watch?v=mHEUlPFT6xg&ab_channel=AmazonWebServices\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_featurestore.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-create-a-dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "historical_df = pd.read_csv(\"historical_data.csv\")\n",
    "\n",
    "# Convert purchase_timestamp to datetime\n",
    "historical_df['purchase_timestamp'] = pd.to_datetime(historical_df['purchase_timestamp'])\n",
    "\n",
    "# Sort the dataframe by customer_id and purchase_timestamp\n",
    "historical_df = historical_df.sort_values(['customer_id', 'purchase_timestamp'])\n",
    "\n",
    "# Function to calculate average of past purchases\n",
    "def past_purchases_avg(group):\n",
    "    return group.shift(1).expanding().mean()\n",
    "\n",
    "# Calculate the average of past purchases for each customer\n",
    "historical_df['avg_past_purchases'] = historical_df.groupby('customer_id')['purchase_value'].transform(past_purchases_avg)\n",
    "\n",
    "# Replace NaN (for first purchases) with 0\n",
    "historical_df['avg_past_purchases'] = historical_df['avg_past_purchases'].fillna(0)\n",
    "\n",
    "historical_df = historical_df[['customer_id', 'purchase_timestamp', 'purchase_value', 'avg_past_purchases', 'loyalty_score']]\n",
    "\n",
    "historical_df.head(50)\n",
    "# # Display the first few rows of the updated dataframe\n",
    "# print(historical_df.head(20))\n",
    "\n",
    "# # Display summary statistics\n",
    "# print(historical_df.describe())\n",
    "\n",
    "# # Verify first purchases\n",
    "# first_purchases = historical_df.groupby('customer_id').first()\n",
    "# print(\"\\nFirst purchases for each customer:\")\n",
    "# print(first_purchases[['purchase_value', 'avg_past_purchases']].head())\n",
    "\n",
    "# # Verify subsequent purchases\n",
    "# print(\"\\nSubsequent purchases for a sample customer:\")\n",
    "# print(historical_df[historical_df['customer_id'] == historical_df['customer_id'].iloc[0]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSubsequent purchases for a sample customer:\")\n",
    "print(historical_df[historical_df['customer_id'] == historical_df['customer_id'].iloc[0]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "historical_df = pd.read_csv(\"historical_data.csv\")\n",
    "historical_df = historical_df.sort_values(\"purchase_timestamp\")\n",
    "historical_df\n",
    "# # Calculate features per customer\n",
    "customer_features = (\n",
    "    historical_df.groupby(\"customer_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"purchase_value\": [\"mean\", \"last\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "customer_features.columns = [\n",
    "    \"customer_id\",\n",
    "    \"avg_purchase_value\",\n",
    "    \"latest_purchase_value\",\n",
    "    \"loyalty_score\",\n",
    "]\n",
    "\n",
    "# # Add event time\n",
    "# customer_features[\"purchase_timestamp\"] = datetime.now().isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import (\n",
    "    FeatureDefinition,\n",
    "    FeatureTypeEnum,\n",
    ")\n",
    "from sagemaker.session import Session\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerMappingStore:\n",
    "    def __init__(self, table_name, region_name):\n",
    "        self.table_name = table_name\n",
    "        self.dynamodb = boto3.resource('dynamodb', region_name=region_name)\n",
    "        self.table = self.dynamodb.Table(table_name)\n",
    "\n",
    "    def create_table(self):\n",
    "        \"\"\"Create DynamoDB table for customer_id to record_id mapping\"\"\"\n",
    "        try:\n",
    "            self.dynamodb.create_table(\n",
    "                TableName=self.table_name,\n",
    "                KeySchema=[\n",
    "                    {'AttributeName': 'customer_id', 'KeyType': 'HASH'}\n",
    "                ],\n",
    "                AttributeDefinitions=[\n",
    "                    {'AttributeName': 'customer_id', 'AttributeType': 'S'}\n",
    "                ],\n",
    "                BillingMode='PAY_PER_REQUEST'\n",
    "            )\n",
    "            print(f\"Created mapping table {self.table_name}\")\n",
    "            time.sleep(10)  # Wait for table creation\n",
    "            self.table = self.dynamodb.Table(self.table_name)\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] != 'ResourceInUseException':\n",
    "                raise\n",
    "\n",
    "    def batch_update_mappings(self, mappings):\n",
    "        \"\"\"Batch update customer_id to record_id mappings\"\"\"\n",
    "        try:\n",
    "            with self.table.batch_writer() as batch:\n",
    "                for item in mappings:\n",
    "                    batch.put_item(\n",
    "                        Item={\n",
    "                            'customer_id': str(item['customer_id']),\n",
    "                            'record_id': str(item['record_id']),\n",
    "                            'last_updated': int(time.time())\n",
    "                        }\n",
    "                    )\n",
    "            print(f\"Updated {len(mappings)} customer mappings\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error batch updating mappings: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_latest_record_id(self, customer_id):\n",
    "        \"\"\"Get the latest record_id for a customer\"\"\"\n",
    "        try:\n",
    "            response = self.table.get_item(\n",
    "                Key={'customer_id': str(customer_id)}\n",
    "            )\n",
    "            if 'Item' in response:\n",
    "                return response['Item']['record_id']\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting mapping for customer {customer_id}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SageMakerFeatureStore:\n",
    "    def __init__(self, sagemaker_session, s3_bucket=None):\n",
    "        self.sagemaker_session = sagemaker_session\n",
    "        self.feature_group = None\n",
    "        self.s3_bucket = s3_bucket or f\"sagemaker-{self.sagemaker_session.boto_region_name}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_record_id(customer_id, timestamp):\n",
    "        \"\"\"Create a composite record_id from customer_id and timestamp\"\"\"\n",
    "        if isinstance(timestamp, str):\n",
    "            timestamp = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        timestamp_str = timestamp.strftime('%Y%m%d%H%M%S')\n",
    "        return f\"CUST{customer_id}_{timestamp_str}\"\n",
    "\n",
    "    def wait_for_feature_group_creation_complete(self, feature_group):\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "        while status == \"Creating\":\n",
    "            print(\"Waiting for Feature Group Creation\")\n",
    "            time.sleep(5)\n",
    "            status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "        if status != \"Created\":\n",
    "            raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "        print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "    def create_feature_group(self, feature_group_name, role_arn):\n",
    "        \"\"\"Create feature group with feature definitions\"\"\"\n",
    "        self.feature_group = FeatureGroup(\n",
    "            name=feature_group_name,\n",
    "            feature_definitions=[\n",
    "                FeatureDefinition(\"record_id\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"customer_id\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"purchase_timestamp\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "                FeatureDefinition(\"avg_purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "                FeatureDefinition(\"loyalty_score\", FeatureTypeEnum.FRACTIONAL),\n",
    "            ],\n",
    "            sagemaker_session=self.sagemaker_session,\n",
    "        )\n",
    "\n",
    "        self.feature_group.create(\n",
    "            s3_uri=f\"s3://{self.s3_bucket}/feature-store/{feature_group_name}\",\n",
    "            record_identifier_name=\"record_id\",\n",
    "            event_time_feature_name=\"purchase_timestamp\",\n",
    "            role_arn=role_arn,\n",
    "            enable_online_store=True,\n",
    "        )\n",
    "\n",
    "        self.wait_for_feature_group_creation_complete(self.feature_group)\n",
    "\n",
    "    def prepare_features(self, historical_df):\n",
    "        \"\"\"Calculate features from historical data\"\"\"\n",
    "        # Convert and format timestamp\n",
    "        historical_df[\"purchase_timestamp\"] = pd.to_datetime(historical_df[\"purchase_timestamp\"])\n",
    "        historical_df[\"purchase_timestamp\"] = historical_df[\"purchase_timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "        # Sort the dataframe\n",
    "        historical_df = historical_df.sort_values([\"customer_id\", \"purchase_timestamp\"])\n",
    "\n",
    "        # Calculate average purchase values\n",
    "        historical_df[\"avg_purchase_value\"] = historical_df.groupby(\"customer_id\")[\"purchase_value\"].transform(\n",
    "            lambda x: x.shift(1).expanding().mean()\n",
    "        ).fillna(0)\n",
    "\n",
    "        # Generate record IDs\n",
    "        historical_df['record_id'] = historical_df.apply(\n",
    "            lambda row: self.create_record_id(\n",
    "                row['customer_id'],\n",
    "                datetime.strptime(row['purchase_timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        return historical_df[\n",
    "            [\"record_id\", \"customer_id\", \"purchase_timestamp\", \"purchase_value\", \n",
    "             \"avg_purchase_value\", \"loyalty_score\"]\n",
    "        ]\n",
    "\n",
    "    def ingest_features(self, features_df):\n",
    "        \"\"\"Ingest features into Feature Store\"\"\"\n",
    "        if self.feature_group is None:\n",
    "            raise ValueError(\"Feature group not created. Call create_feature_group first.\")\n",
    "        \n",
    "        self.feature_group.ingest(data_frame=features_df, max_workers=1, wait=True)\n",
    "        return features_df[['customer_id', 'record_id']].to_dict('records')\n",
    "\n",
    "    def get_record(self, record_id):\n",
    "        \"\"\"Retrieve a specific record from the feature store\"\"\"\n",
    "        feature_store_runtime = boto3.Session().client(\n",
    "            service_name=\"sagemaker-featurestore-runtime\",\n",
    "            region_name=self.sagemaker_session.boto_region_name\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = feature_store_runtime.get_record(\n",
    "                FeatureGroupName=self.feature_group.name,\n",
    "                RecordIdentifierValueAsString=record_id\n",
    "            )\n",
    "            \n",
    "            features = {}\n",
    "            for feature in response[\"Record\"]:\n",
    "                features[feature[\"FeatureName\"]] = feature[\"ValueAsString\"]\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving record {record_id}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Configuration\n",
    "FEATURE_GROUP_NAME = \"customer_purchase_features\"\n",
    "MAPPING_TABLE_NAME = \"customer_record_mapping\"\n",
    "ROLE_ARN = \"arn:aws:iam::YOUR_ACCOUNT_ID:role/YOUR_ROLE_NAME\"\n",
    "\n",
    "feature_store = SageMakerFeatureStore(sagemaker_session)\n",
    "mapping_store = CustomerMappingStore(MAPPING_TABLE_NAME, sagemaker_session.boto_region_name)\n",
    "\n",
    "mapping_store.create_table()\n",
    "feature_store.create_feature_group(FEATURE_GROUP_NAME, ROLE_ARN)\n",
    "\n",
    "\n",
    "features_df = feature_store.prepare_features(historical_df)       \n",
    "# Ingest to feature store and get mappings\n",
    "mappings = feature_store.ingest_features(features_df)\n",
    "# Update mapping store\n",
    "mapping_store.batch_update_mappings(mappings)\n",
    "\n",
    "\n",
    "record_id = mapping_store.get_latest_record_id('100')\n",
    "if not record_id:\n",
    "    print(None)\n",
    "feature_store.get_record(record_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from botocore.exceptions import ClientError\n",
    "# class FeatureStoreManager:\n",
    "#     def __init__(self, sagemaker_session, mapping_table_name=\"customer_record_mapping\"):\n",
    "#         self.sagemaker_session = sagemaker_session\n",
    "#         self.feature_group = None\n",
    "#         self.s3_bucket = default_s3_bucket_name\n",
    "#         self.mapping_table_name = mapping_table_name\n",
    "        \n",
    "#         # Initialize DynamoDB client\n",
    "#         self.dynamodb = boto3.resource('dynamodb', region_name=self.sagemaker_session.boto_region_name)\n",
    "#         self.mapping_table = self.dynamodb.Table(mapping_table_name)\n",
    "\n",
    "#     def create_mapping_table(self):\n",
    "#         \"\"\"Create DynamoDB table for customer_id to record_id mapping if it doesn't exist\"\"\"\n",
    "#         try:\n",
    "#             self.dynamodb.create_table(\n",
    "#                 TableName=self.mapping_table_name,\n",
    "#                 KeySchema=[\n",
    "#                     {'AttributeName': 'customer_id', 'KeyType': 'HASH'}\n",
    "#                 ],\n",
    "#                 AttributeDefinitions=[\n",
    "#                     {'AttributeName': 'customer_id', 'AttributeType': 'S'}\n",
    "#                 ],\n",
    "#                 BillingMode='PAY_PER_REQUEST'\n",
    "#             )\n",
    "#             print(f\"Created mapping table {self.mapping_table_name}\")\n",
    "#             # Wait for table to be created\n",
    "#             time.sleep(10)\n",
    "#         except ClientError as e:\n",
    "#             if e.response['Error']['Code'] != 'ResourceInUseException':\n",
    "#                 raise\n",
    "\n",
    "#     def update_customer_mapping(self, customer_id, record_id):\n",
    "#         \"\"\"Update the mapping of customer_id to latest record_id\"\"\"\n",
    "#         try:\n",
    "#             self.mapping_table.put_item(\n",
    "#                 Item={\n",
    "#                     'customer_id': str(customer_id),\n",
    "#                     'record_id': str(record_id),\n",
    "#                     'last_updated': int(time.time())\n",
    "#                 }\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error updating mapping for customer {customer_id}: {e}\")\n",
    "#             raise\n",
    "\n",
    "#     def batch_update_mappings(self, mappings):\n",
    "#         \"\"\"\n",
    "#         Batch update customer_id to record_id mappings\n",
    "        \n",
    "#         Args:\n",
    "#             mappings: List of dictionaries containing customer_id and record_id\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             with self.mapping_table.batch_writer() as batch:\n",
    "#                 for item in mappings:\n",
    "#                     batch.put_item(\n",
    "#                         Item={\n",
    "#                             'customer_id': str(item['customer_id']),\n",
    "#                             'record_id': str(item['record_id']),\n",
    "#                             'last_updated': int(time.time())\n",
    "#                         }\n",
    "#                     )\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error batch updating mappings: {e}\")\n",
    "#             raise\n",
    "\n",
    "#     def get_latest_record_id(self, customer_id):\n",
    "#         \"\"\"Get the latest record_id for a customer\"\"\"\n",
    "#         try:\n",
    "#             response = self.mapping_table.get_item(\n",
    "#                 Key={'customer_id': str(customer_id)}\n",
    "#             )\n",
    "#             if 'Item' in response:\n",
    "#                 return response['Item']['record_id']\n",
    "#             return None\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error getting mapping for customer {customer_id}: {e}\")\n",
    "#             return None\n",
    "\n",
    "#     @staticmethod\n",
    "#     def create_record_id(customer_id, timestamp):\n",
    "#         \"\"\"\n",
    "#         Create a composite record_id from customer_id and timestamp\n",
    "#         Format: CUST{customer_id}_{timestamp}\n",
    "#         \"\"\"\n",
    "#         if isinstance(timestamp, str):\n",
    "#             # Convert ISO format to datetime\n",
    "#             timestamp = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "#         timestamp_str = timestamp.strftime('%Y%m%d%H%M%S')\n",
    "#         return f\"CUST{customer_id}_{timestamp_str}\"\n",
    "\n",
    "#     def wait_for_feature_group_creation_complete(self, feature_group):\n",
    "#         status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "#         while status == \"Creating\":\n",
    "#             print(\"Waiting for Feature Group Creation\")\n",
    "#             time.sleep(5)\n",
    "#             status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "#         if status != \"Created\":\n",
    "#             raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "#         print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "#     def create_feature_group(self):\n",
    "#         \"\"\"Create feature group with updated feature definitions\"\"\"\n",
    "#         self.feature_group = FeatureGroup(\n",
    "#             name=\"customer_purchase_features\",\n",
    "#             feature_definitions=[\n",
    "#                 FeatureDefinition(\"record_id\", FeatureTypeEnum.STRING),\n",
    "#                 FeatureDefinition(\"customer_id\", FeatureTypeEnum.INTEGRAL),\n",
    "#                 FeatureDefinition(\"purchase_timestamp\", FeatureTypeEnum.STRING),\n",
    "#                 FeatureDefinition(\"purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "#                 FeatureDefinition(\"avg_purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "#                 FeatureDefinition(\"loyalty_score\", FeatureTypeEnum.FRACTIONAL),\n",
    "#             ],\n",
    "#             sagemaker_session=self.sagemaker_session,\n",
    "#         )\n",
    "\n",
    "#         self.feature_group.create(\n",
    "#             s3_uri=f\"s3://{self.s3_bucket}/feature-store/customer_features\",\n",
    "#             record_identifier_name=\"record_id\",\n",
    "#             event_time_feature_name=\"purchase_timestamp\",\n",
    "#             role_arn=role,\n",
    "#             enable_online_store=True,\n",
    "#         )\n",
    "\n",
    "#         self.wait_for_feature_group_creation_complete(self.feature_group)\n",
    "        \n",
    "#         # Create the mapping table after feature group is created\n",
    "#         self.create_mapping_table()\n",
    "\n",
    "#     def prepare_initial_features(self, historical_df):\n",
    "#         \"\"\"Calculate initial features from historical data\"\"\"\n",
    "#         # Convert purchase_timestamp to datetime\n",
    "#         historical_df[\"purchase_timestamp\"] = pd.to_datetime(\n",
    "#             historical_df[\"purchase_timestamp\"]\n",
    "#         )\n",
    "\n",
    "#         # Ensure purchase_timestamp is in correct ISO format\n",
    "#         historical_df[\"purchase_timestamp\"] = historical_df[\"purchase_timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "#         # Sort the dataframe by customer_id and purchase_timestamp\n",
    "#         historical_df = historical_df.sort_values([\"customer_id\", \"purchase_timestamp\"])\n",
    "\n",
    "#         # Function to calculate average of past purchases\n",
    "#         def past_purchases_avg(group):\n",
    "#             return group.shift(1).expanding().mean()\n",
    "\n",
    "#         # Calculate the average of past purchases for each customer\n",
    "#         historical_df[\"avg_purchase_value\"] = historical_df.groupby(\"customer_id\")[\n",
    "#             \"purchase_value\"\n",
    "#         ].transform(past_purchases_avg)\n",
    "\n",
    "#         # Replace NaN (for first purchases) with 0\n",
    "#         historical_df[\"avg_purchase_value\"] = historical_df[\n",
    "#             \"avg_purchase_value\"\n",
    "#         ].fillna(0)\n",
    "\n",
    "#         # Generate record IDs using the new format\n",
    "#         historical_df['record_id'] = historical_df.apply(\n",
    "#             lambda row: self.create_record_id(\n",
    "#                 row['customer_id'], \n",
    "#                 datetime.strptime(row['purchase_timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "#             ),\n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#         historical_df = historical_df[\n",
    "#             [   \n",
    "#                 \"record_id\",\n",
    "#                 \"customer_id\",\n",
    "#                 \"purchase_timestamp\",\n",
    "#                 \"purchase_value\",\n",
    "#                 \"avg_purchase_value\",\n",
    "#                 \"loyalty_score\",\n",
    "#             ]\n",
    "#         ]\n",
    "\n",
    "#         return historical_df\n",
    "\n",
    "#     def ingest_features(self, features_df):\n",
    "#         \"\"\"\n",
    "#         Ingest features into Feature Store and update DynamoDB mappings\n",
    "        \n",
    "#         Args:\n",
    "#             features_df: DataFrame containing features to ingest\n",
    "#         \"\"\"\n",
    "#         # First ingest the features\n",
    "#         self.feature_group.ingest(data_frame=features_df, max_workers=1, wait=True)\n",
    "        \n",
    "#         # After successful ingestion, update the DynamoDB mappings\n",
    "#         # Group by customer_id and get the latest record for each customer\n",
    "#         latest_records = features_df.sort_values('purchase_timestamp').groupby('customer_id').last().reset_index()\n",
    "        \n",
    "#         # Prepare mappings for batch update\n",
    "#         mappings = [\n",
    "#             {\n",
    "#                 'customer_id': str(row['customer_id']),\n",
    "#                 'record_id': str(row['record_id'])\n",
    "#             }\n",
    "#             for _, row in latest_records.iterrows()\n",
    "#         ]\n",
    "        \n",
    "#         # Update DynamoDB mappings in batch\n",
    "#         self.batch_update_mappings(mappings)\n",
    "        \n",
    "#         print(f\"Ingested {len(features_df)} records and updated {len(mappings)} customer mappings\")\n",
    "\n",
    "#     def get_latest_features(self, customer_id):\n",
    "#         \"\"\"Retrieve latest features for a customer from online store\"\"\"\n",
    "#         feature_store_runtime = boto3.Session().client(\n",
    "#             service_name=\"sagemaker-featurestore-runtime\", \n",
    "#             region_name=self.sagemaker_session.boto_region_name\n",
    "#         )\n",
    "\n",
    "#         try:\n",
    "#             # Get the latest record_id from DynamoDB\n",
    "#             record_id = self.get_latest_record_id(customer_id)\n",
    "#             if not record_id:\n",
    "#                 print(f\"No record_id mapping found for customer {customer_id}\")\n",
    "#                 return None\n",
    "\n",
    "#             # Get the record using the record_id\n",
    "#             response = feature_store_runtime.get_record(\n",
    "#                 FeatureGroupName=self.feature_group.name,\n",
    "#                 RecordIdentifierValueAsString=record_id\n",
    "#             )\n",
    "            \n",
    "#             # Convert to dictionary format\n",
    "#             features = {}\n",
    "#             for feature in response[\"Record\"]:\n",
    "#                 features[feature[\"FeatureName\"]] = feature[\"ValueAsString\"]\n",
    "#             return features\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error retrieving features for customer {customer_id}: {e}\")\n",
    "#             return None\n",
    "\n",
    "#     def update_customer_features(self, customer_id, new_purchase_value, new_loyalty_score):\n",
    "#         \"\"\"Update customer features with new purchase data\"\"\"\n",
    "#         current_features = self.get_latest_features(customer_id)\n",
    "\n",
    "#         if current_features:\n",
    "#             # Calculate new averages\n",
    "#             old_avg_purchase = float(current_features[\"avg_purchase_value\"])\n",
    "#             new_avg_purchase = (old_avg_purchase + new_purchase_value) / 2\n",
    "#         else:\n",
    "#             new_avg_purchase = new_purchase_value\n",
    "\n",
    "#         # Format current timestamp in ISO-8601 format\n",
    "#         current_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "#         # Generate new record ID using the composite format\n",
    "#         new_record_id = self.create_record_id(customer_id, datetime.now())\n",
    "\n",
    "#         # Prepare new record\n",
    "#         record = {\n",
    "#             \"record_id\": new_record_id,\n",
    "#             \"customer_id\": str(customer_id),\n",
    "#             \"purchase_timestamp\": current_time,\n",
    "#             \"purchase_value\": str(new_purchase_value),\n",
    "#             \"avg_purchase_value\": str(new_avg_purchase),\n",
    "#             \"loyalty_score\": str(new_loyalty_score),\n",
    "#         }\n",
    "\n",
    "#         # Update feature store\n",
    "#         feature_store_runtime = boto3.Session().client(\n",
    "#             service_name=\"sagemaker-featurestore-runtime\",\n",
    "#             region_name=self.sagemaker_session.boto_region_name\n",
    "#         )\n",
    "\n",
    "#         feature_store_runtime.put_record(\n",
    "#             FeatureGroupName=self.feature_group.name,\n",
    "#             Record=[{\"FeatureName\": k, \"ValueAsString\": v} for k, v in record.items()],\n",
    "#         )\n",
    "\n",
    "#         # Update the DynamoDB mapping\n",
    "#         self.update_customer_mapping(customer_id, new_record_id)\n",
    "\n",
    "#         return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_s3_bucket_name = feature_store_session.default_bucket()\n",
    "prefix = \"sagemaker-featurestore-demo\"\n",
    "role = \"arn:aws:iam::210399391398:role/service-role/AmazonSageMaker-ExecutionRole-20241221T151049\"\n",
    "\n",
    "print(default_s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStoreManager:\n",
    "    def __init__(self, sagemaker_session):\n",
    "        self.sagemaker_session = sagemaker_session\n",
    "        self.feature_group = None\n",
    "        self.s3_bucket = default_s3_bucket_name\n",
    "\n",
    "    # @staticmethod\n",
    "    # def create_record_id(customer_id, timestamp):\n",
    "    #     \"\"\"Create a composite record_id from customer_id and timestamp\"\"\"\n",
    "    #     if isinstance(timestamp, str):\n",
    "    #         timestamp = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    #     timestamp_str = timestamp.strftime('%Y%m%d%H%M%S')\n",
    "    #     return f\"CUST{customer_id}_{timestamp_str}\"\n",
    "\n",
    "    def wait_for_feature_group_creation_complete(self, feature_group):\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "        while status == \"Creating\":\n",
    "            print(\"Waiting for Feature Group Creation\")\n",
    "            time.sleep(5)\n",
    "            status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "        if status != \"Created\":\n",
    "            raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "        print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "    def create_feature_group(self):\n",
    "        \"\"\"Create feature group with updated feature definitions\"\"\"\n",
    "        self.feature_group = FeatureGroup(\n",
    "            name=\"customer_purchase_features\",\n",
    "            feature_definitions=[\n",
    "                #FeatureDefinition(\"record_id\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"customer_id\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"purchase_timestamp\", FeatureTypeEnum.STRING),\n",
    "                FeatureDefinition(\"latest_purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "                FeatureDefinition(\"avg_purchase_value\", FeatureTypeEnum.FRACTIONAL),\n",
    "                FeatureDefinition(\"latest_loyalty_score\", FeatureTypeEnum.FRACTIONAL),\n",
    "                FeatureDefinition(\"avg_loyalty_score\", FeatureTypeEnum.FRACTIONAL),\n",
    "            ],\n",
    "            sagemaker_session=self.sagemaker_session,\n",
    "        )\n",
    "\n",
    "        self.feature_group.create(\n",
    "            s3_uri=f\"s3://{self.s3_bucket}/feature-store/customer_features\",\n",
    "            record_identifier_name=\"customer_id\",\n",
    "            event_time_feature_name=\"purchase_timestamp\",\n",
    "            role_arn=role,\n",
    "            enable_online_store=True,\n",
    "        )\n",
    "\n",
    "        self.wait_for_feature_group_creation_complete(self.feature_group)\n",
    "\n",
    "    def prepare_initial_features(self, historical_df):\n",
    "        \"\"\"Calculate initial features from historical data\"\"\"\n",
    "        # Convert purchase_timestamp to datetime\n",
    "        historical_df[\"purchase_timestamp\"] = pd.to_datetime(historical_df[\"purchase_timestamp\"])\n",
    "        \n",
    "        # Group by customer_id to calculate features\n",
    "        customer_features = historical_df.groupby('customer_id').agg({\n",
    "            'purchase_timestamp': 'max',  # Get the latest timestamp\n",
    "            'purchase_value': ['last', 'mean'],  # Get latest and average purchase\n",
    "            'loyalty_score': ['last', 'mean']  # Get latest and average loyalty score\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten column names\n",
    "        customer_features.columns = [\n",
    "            'customer_id', 'purchase_timestamp', \n",
    "            'latest_purchase_value', 'avg_purchase_value',\n",
    "            'latest_loyalty_score', 'avg_loyalty_score'\n",
    "        ]\n",
    "        \n",
    "        # Format timestamp\n",
    "        customer_features[\"purchase_timestamp\"] = customer_features[\"purchase_timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        # Generate record IDs\n",
    "        # customer_features['record_id'] = customer_features.apply(\n",
    "        #     lambda row: self.create_record_id(\n",
    "        #         row['customer_id'], \n",
    "        #         datetime.strptime(row['purchase_timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        #     ),\n",
    "        #     axis=1\n",
    "        # )\n",
    "\n",
    "        return customer_features\n",
    "\n",
    "    def ingest_features(self, features_df):\n",
    "        \"\"\"Ingest features into Feature Store\"\"\"\n",
    "        self.feature_group.ingest(data_frame=features_df, max_workers=1, wait=True)\n",
    "    \n",
    "    # Helper to parse the feature value from the record.\n",
    "    def get_feature_value(self, record, feature_name):\n",
    "        return str(list(filter(lambda r: r[\"FeatureName\"] == feature_name, record))[0][\"ValueAsString\"])\n",
    "\n",
    "    def get_latest_features(self, customer_id):\n",
    "        \"\"\"Retrieve latest features for a customer from online store\"\"\"\n",
    "        feature_store_runtime = boto3.Session().client(\n",
    "            service_name=\"sagemaker-featurestore-runtime\", \n",
    "            region_name=self.sagemaker_session.boto_region_name\n",
    "        )\n",
    "\n",
    "        # record_identifier_value = \"100\"\n",
    "\n",
    "        # featurestore_runtime.get_record(\n",
    "        #     FeatureGroupName=\"customer_purchase_features\",\n",
    "        #     RecordIdentifierValueAsString=record_identifier_value,\n",
    "        # )\n",
    "\n",
    "        #try:\n",
    "        print(customer_id)\n",
    "        response = feature_store_runtime.get_record(FeatureGroupName=\"customer_purchase_features\", RecordIdentifierValueAsString=customer_id)\n",
    "        if 'Record' not in response:\n",
    "            print(f\"No records found for customer {customer_id}\")\n",
    "            return None \n",
    "        record = response[\"Record\"]\n",
    "\n",
    "        customer_features = {\n",
    "            \"customer_id\": self.get_feature_value(record, \"customer_id\"),\n",
    "            \"purchase_timestamp\": self.get_feature_value(record, \"purchase_timestamp\"),\n",
    "            \"latest_purchase_value\": self.get_feature_value(record, \"latest_purchase_value\"),\n",
    "            \"avg_purchase_value\": self.get_feature_value(record, \"avg_purchase_value\"),\n",
    "            \"latest_loyalty_score\": self.get_feature_value(record, \"latest_loyalty_score\"),\n",
    "            \"avg_loyalty_score\": self.get_feature_value(record, \"avg_loyalty_score\"),\n",
    "        }\n",
    "        \n",
    "        # # Sort records by record_id (which includes timestamp) to get the latest\n",
    "        # records = response['Records'][0]\n",
    "        # latest_record = max(records, key=lambda x: x['RecordIdentifier'])\n",
    "        \n",
    "        # Convert to dictionary format\n",
    "        # features = {}\n",
    "        # for feature in response[\"Record\"]:\n",
    "        #     features[feature[\"FeatureName\"]] = feature[\"ValueAsString\"]\n",
    "        \n",
    "        return customer_features\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Customer {customer_id} not found in feature store: {e}\")\n",
    "        #     return None\n",
    "\n",
    "    def update_customer_features(self, customer_id, new_purchase_value, new_loyalty_score):\n",
    "        \"\"\"Update customer features with new purchase data and predicted loyalty score\"\"\"\n",
    "        current_features = self.get_latest_features(customer_id)\n",
    "\n",
    "        if current_features:\n",
    "            # Calculate new averages\n",
    "            old_avg_purchase = float(current_features[\"avg_purchase_value\"])\n",
    "            new_avg_purchase = (old_avg_purchase + new_purchase_value) / 2\n",
    "            \n",
    "            old_avg_loyalty = float(current_features[\"avg_loyalty_score\"])\n",
    "            new_avg_loyalty = (old_avg_loyalty + new_loyalty_score) / 2\n",
    "        else:\n",
    "            new_avg_purchase = new_purchase_value\n",
    "            new_avg_loyalty = new_loyalty_score\n",
    "\n",
    "        # Format current timestamp\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        # Generate new record ID\n",
    "        #new_record_id = self.create_record_id(customer_id, datetime.now())\n",
    "\n",
    "        # Prepare new record\n",
    "        record = {\n",
    "            \"customer_id\": str(customer_id),\n",
    "            \"purchase_timestamp\": current_time,\n",
    "            \"latest_purchase_value\": str(new_purchase_value),\n",
    "            \"avg_purchase_value\": str(new_avg_purchase),\n",
    "            \"latest_loyalty_score\": str(new_loyalty_score),\n",
    "            \"avg_loyalty_score\": str(new_avg_loyalty)\n",
    "        }\n",
    "\n",
    "        # Update feature store\n",
    "        feature_store_runtime = boto3.Session().client(\n",
    "            service_name=\"sagemaker-featurestore-runtime\", \n",
    "            region_name=self.sagemaker_session.boto_region_name\n",
    "        )\n",
    "\n",
    "        feature_store_runtime.put_record(\n",
    "            FeatureGroupName=self.feature_group.name,\n",
    "            Record=[{\"FeatureName\": k, \"ValueAsString\": v} for k, v in record.items()],\n",
    "        )\n",
    "\n",
    "        return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = pd.read_csv(\"historical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager = FeatureStoreManager(feature_store_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.create_feature_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_store_manager.feature_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = feature_store_manager.prepare_initial_features(historical_df)\n",
    "initial_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features[initial_features['customer_id']==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.ingest_features(initial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get data of one record to verify insertion\n",
    "\n",
    "record_identifier_value = \"100\"\n",
    "\n",
    "featurestore_runtime.get_record(\n",
    "    FeatureGroupName=\"customer_purchase_features\",\n",
    "    RecordIdentifierValueAsString=record_identifier_value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurestore_runtime.batch_get_record(\n",
    "#     Identifiers=[\n",
    "#         {\n",
    "#             \"FeatureGroupName\": \"customer_purchase_features\",\n",
    "#             \"RecordIdentifiersValueAsString\": [\"100\"],\n",
    "#         },\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "print(account_id)\n",
    "\n",
    "feature_group_resolved_output_s3_uri = (\n",
    "    feature_store_manager.feature_group.describe()\n",
    "    .get(\"OfflineStoreConfig\")\n",
    "    .get(\"S3StorageConfig\")\n",
    "    .get(\"ResolvedOutputS3Uri\")\n",
    ")\n",
    "feature_group_resolved_output_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_s3_prefix = feature_group_resolved_output_s3_uri.replace(\n",
    "    f\"s3://{default_s3_bucket_name}/\", \"\"\n",
    ")\n",
    "feature_group_s3_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "offline_store_contents = None\n",
    "while offline_store_contents is None:\n",
    "    objects_in_bucket = s3_client.list_objects(\n",
    "        Bucket=default_s3_bucket_name, Prefix=feature_group_s3_prefix\n",
    "    )\n",
    "    if \"Contents\" in objects_in_bucket and len(objects_in_bucket[\"Contents\"]) > 1:\n",
    "        offline_store_contents = objects_in_bucket[\"Contents\"]\n",
    "    else:\n",
    "        print(\"Waiting for data in offline store...\\n\")\n",
    "        sleep(60)\n",
    "\n",
    "print(\"Data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    @staticmethod\n",
    "    def build_training_dataset(feature_store_manager):\n",
    "        \"\"\"Build training dataset from Feature Store\"\"\"\n",
    "        try:\n",
    "            customer_query = feature_store_manager.feature_group.athena_query()\n",
    "            customer_table = customer_query.table_name\n",
    "            \n",
    "            query_string = f\"\"\"\n",
    "            SELECT \n",
    "                customer_id,\n",
    "                latest_purchase_value,\n",
    "                avg_purchase_value,\n",
    "                latest_loyalty_score,\n",
    "                avg_loyalty_score\n",
    "            FROM \"{customer_table}\"\n",
    "            ORDER BY customer_id, purchase_timestamp DESC\n",
    "            \"\"\"\n",
    "            \n",
    "            customer_query.run(\n",
    "                query_string=query_string,\n",
    "                output_location=f\"s3://{default_s3_bucket_name}/query_results/\"\n",
    "            )\n",
    "            customer_query.wait()\n",
    "            train_df = customer_query.as_dataframe()\n",
    "            \n",
    "            # Prepare features and target\n",
    "            X = train_df[['latest_purchase_value', 'avg_purchase_value', 'avg_loyalty_score']]\n",
    "            y = train_df['latest_loyalty_score']  # Current loyalty score becomes target\n",
    "            \n",
    "            return X, y\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in build_training_dataset: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def train_model(X, y):\n",
    "        \"\"\"Train a simple linear regression model\"\"\"\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Save model locally\n",
    "        with open('loyalty_predictor.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Usage example\n",
    "print(\"\\nTraining model using Feature Store data...\")\n",
    "trainer = ModelTrainer()\n",
    "X, y = trainer.build_training_dataset(feature_store_manager)\n",
    "model = trainer.train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.get_latest_features(customer_id=str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.update_customer_features(\n",
    "str(1),\n",
    "400,\n",
    "3  # Use predicted loyalty score as the new latest_loyalty_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeInference:\n",
    "    def __init__(self, feature_store_manager, model_path='loyalty_predictor.pkl'):\n",
    "        self.feature_store_manager = feature_store_manager\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "    def process_event(self, event):\n",
    "        \"\"\"Process a single real-time event\"\"\"\n",
    "        customer_id = event['customer_id']\n",
    "        purchase_amount = float(event['purchase_value'])\n",
    "        #real_loyalty = float(event['loyalty_score'])\n",
    "\n",
    "        # Get historical features\n",
    "        customer_features = self.feature_store_manager.get_latest_features(customer_id)\n",
    "        \n",
    "        if customer_features:\n",
    "            # in case customer already processed we enrich the data from feature store\n",
    "            features = {\n",
    "                'latest_purchase_value': purchase_amount,\n",
    "                'avg_purchase_value': float(customer_features['avg_purchase_value']),\n",
    "                #'latest_loyalty_score': float(customer_features['latest_loyalty_score']),\n",
    "                'avg_loyalty_score': float(customer_features['avg_loyalty_score'])\n",
    "            }\n",
    "        else:\n",
    "            new_customer_loyalty_score = 0\n",
    "            features = {\n",
    "                'latest_purchase_value': purchase_amount,\n",
    "                'avg_purchase_value': purchase_amount,\n",
    "                #'latest_loyalty_score': new_customer_loyalty_score,\n",
    "                'avg_loyalty_score': new_customer_loyalty_score\n",
    "            }\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([[\n",
    "            features['latest_purchase_value'],\n",
    "            features['avg_purchase_value'],\n",
    "            #features['latest_loyalty_score'],\n",
    "            features['avg_loyalty_score']\n",
    "        ]])[0]\n",
    "\n",
    "        # Update feature store with predicted loyalty score\n",
    "        self.feature_store_manager.update_customer_features(\n",
    "            customer_id,\n",
    "            purchase_amount,\n",
    "            prediction  # Use predicted loyalty score as the new latest_loyalty_score\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'predicted_loyalty': prediction,\n",
    "            #'ground_truth_loyalty': real_loyalty\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"realtime_simulation.csv\")\n",
    "# First, ensure the purchase_timestamp is in datetime format\n",
    "df['purchase_timestamp'] = pd.to_datetime(df['purchase_timestamp'])\n",
    "\n",
    "# Now, sort the DataFrame by purchase_timestamp in ascending order\n",
    "df_sorted = df.sort_values('purchase_timestamp', ascending=True)\n",
    "# If you want to update the original DataFrame\n",
    "df = df_sorted\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "#df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inferencer = RealTimeInference(feature_store_manager)\n",
    "results =[]\n",
    "# Iterate over the DataFrame and create a list of dictionaries\n",
    "events = []\n",
    "for _, row in df.iterrows():\n",
    "    event = {\n",
    "        'customer_id': str(row['customer_id']),\n",
    "        'purchase_value': row['purchase_value'],\n",
    "        #'loyalty_score': row['loyalty_score']\n",
    "    }\n",
    "    result = inferencer.process_event(event)\n",
    "    results.append(result['predicted_loyalty'])\n",
    "    events.append(event)\n",
    "\n",
    "df['prediction'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.get_latest_features(customer_id=str(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure the purchase_timestamp is in datetime format\n",
    "df['purchase_timestamp'] = pd.to_datetime(df['purchase_timestamp'])\n",
    "\n",
    "# Group by customer_id and get the index of the latest purchase for each customer\n",
    "latest_purchase_indices = df.groupby('customer_id')['purchase_timestamp'].idxmax()\n",
    "\n",
    "# Use these indices to select the rows with the latest purchase for each customer\n",
    "latest_purchases = df.loc[latest_purchase_indices]\n",
    "\n",
    "# Sort the result by customer_id for better readability\n",
    "latest_purchases = latest_purchases.sort_values('customer_id')\n",
    "\n",
    "# Reset the index if needed\n",
    "latest_purchases = latest_purchases.reset_index(drop=True)\n",
    "\n",
    "latest_purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_manager.get_latest_features(customer_id=str(95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in latest_purchases.iterrows():\n",
    "    customer = str(row['customer_id'])\n",
    "    d = feature_store_manager.get_latest_features(customer_id=str(customer))\n",
    "    assert d['customer_id'] == customer\n",
    "    assert d['latest_purchase_value'] == str(row['purchase_value'])\n",
    "    assert d['latest_loyalty_score'] == str(row['prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['customer_id']==20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['latest_purchase_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['purchase_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeInference:\n",
    "    def __init__(self, feature_store_manager, model_path='loyalty_predictor.pkl'):\n",
    "        self.feature_store_manager = feature_store_manager\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def process_event(self, event):\n",
    "        \"\"\"Process a single real-time event\"\"\"\n",
    "        customer_id = event['customer_id']\n",
    "        purchase_amount = event['purchase_value']\n",
    "        current_loyalty = event['loyalty_score']\n",
    "        \n",
    "        # Get historical features\n",
    "        customer_features = self.feature_store_manager.get_latest_features(customer_id)\n",
    "        \n",
    "        if customer_features:\n",
    "            features = {\n",
    "                'avg_purchase_amount': float(customer_features['avg_purchase_amount']),\n",
    "                'latest_purchase_amount': purchase_amount,  # Use current purchase as latest\n",
    "                'avg_loyalty_score': float(customer_features['avg_loyalty_score']),\n",
    "                'latest_loyalty_score': float(customer_features['latest_loyalty_score'])\n",
    "            }\n",
    "        else:\n",
    "            features = {\n",
    "                'avg_purchase_amount': purchase_amount,\n",
    "                'latest_purchase_amount': purchase_amount,\n",
    "                'avg_loyalty_score': current_loyalty,\n",
    "                'latest_loyalty_score': current_loyalty\n",
    "            }\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([[\n",
    "            features['avg_purchase_amount'],\n",
    "            features['latest_purchase_amount'],\n",
    "            features['avg_loyalty_score'],\n",
    "            features['latest_loyalty_score']\n",
    "        ]])[0]\n",
    "        \n",
    "        # Update feature store\n",
    "        self.feature_store_manager.update_customer_features(\n",
    "            customer_id,\n",
    "            purchase_amount,\n",
    "            current_loyalty\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'predicted_loyalty': prediction,\n",
    "            'actual_loyalty': current_loyalty\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f=pd.read_csv(\"inspection_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>latest_purchase_timestamp</th>\n",
       "      <th>latest_purchase_value_df</th>\n",
       "      <th>predicted_loyalty_score_df</th>\n",
       "      <th>latest_purchase_value_fs</th>\n",
       "      <th>latest_loyalty_score_fs</th>\n",
       "      <th>avg_purchase_value_fs</th>\n",
       "      <th>avg_loyalty_score_fs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-16 07:23:59</td>\n",
       "      <td>398.50</td>\n",
       "      <td>4.481954</td>\n",
       "      <td>398.50</td>\n",
       "      <td>4.481954</td>\n",
       "      <td>367.421667</td>\n",
       "      <td>3.985977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-08-09 00:54:07</td>\n",
       "      <td>448.05</td>\n",
       "      <td>2.698069</td>\n",
       "      <td>448.05</td>\n",
       "      <td>2.698069</td>\n",
       "      <td>448.050000</td>\n",
       "      <td>2.698069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-04-13 22:26:04</td>\n",
       "      <td>284.28</td>\n",
       "      <td>6.958193</td>\n",
       "      <td>284.28</td>\n",
       "      <td>6.958193</td>\n",
       "      <td>218.560000</td>\n",
       "      <td>7.664097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-14 15:20:27</td>\n",
       "      <td>414.73</td>\n",
       "      <td>6.958654</td>\n",
       "      <td>414.73</td>\n",
       "      <td>6.958654</td>\n",
       "      <td>335.588333</td>\n",
       "      <td>7.609327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-08 02:39:55</td>\n",
       "      <td>44.12</td>\n",
       "      <td>4.413678</td>\n",
       "      <td>44.12</td>\n",
       "      <td>4.413678</td>\n",
       "      <td>232.135000</td>\n",
       "      <td>3.961839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>93</td>\n",
       "      <td>2022-11-01 20:34:21</td>\n",
       "      <td>17.05</td>\n",
       "      <td>6.561586</td>\n",
       "      <td>17.05</td>\n",
       "      <td>6.561586</td>\n",
       "      <td>69.110000</td>\n",
       "      <td>7.162222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>95</td>\n",
       "      <td>2022-03-17 20:43:04</td>\n",
       "      <td>36.65</td>\n",
       "      <td>4.843353</td>\n",
       "      <td>36.65</td>\n",
       "      <td>4.843353</td>\n",
       "      <td>200.718333</td>\n",
       "      <td>4.601676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>96</td>\n",
       "      <td>2022-07-13 14:39:11</td>\n",
       "      <td>30.75</td>\n",
       "      <td>6.282132</td>\n",
       "      <td>30.75</td>\n",
       "      <td>6.282132</td>\n",
       "      <td>136.958333</td>\n",
       "      <td>6.726066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>98</td>\n",
       "      <td>2022-01-08 15:44:58</td>\n",
       "      <td>444.19</td>\n",
       "      <td>6.312584</td>\n",
       "      <td>444.19</td>\n",
       "      <td>6.312584</td>\n",
       "      <td>443.410000</td>\n",
       "      <td>6.621292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-29 16:35:12</td>\n",
       "      <td>40.66</td>\n",
       "      <td>4.031346</td>\n",
       "      <td>40.66</td>\n",
       "      <td>4.031346</td>\n",
       "      <td>120.178333</td>\n",
       "      <td>3.450673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id latest_purchase_timestamp  latest_purchase_value_df  \\\n",
       "0             1       2022-03-16 07:23:59                    398.50   \n",
       "1             2       2022-08-09 00:54:07                    448.05   \n",
       "2             4       2022-04-13 22:26:04                    284.28   \n",
       "3             5       2022-10-14 15:20:27                    414.73   \n",
       "4             6       2022-03-08 02:39:55                     44.12   \n",
       "..          ...                       ...                       ...   \n",
       "59           93       2022-11-01 20:34:21                     17.05   \n",
       "60           95       2022-03-17 20:43:04                     36.65   \n",
       "61           96       2022-07-13 14:39:11                     30.75   \n",
       "62           98       2022-01-08 15:44:58                    444.19   \n",
       "63          100       2022-01-29 16:35:12                     40.66   \n",
       "\n",
       "    predicted_loyalty_score_df  latest_purchase_value_fs  \\\n",
       "0                     4.481954                    398.50   \n",
       "1                     2.698069                    448.05   \n",
       "2                     6.958193                    284.28   \n",
       "3                     6.958654                    414.73   \n",
       "4                     4.413678                     44.12   \n",
       "..                         ...                       ...   \n",
       "59                    6.561586                     17.05   \n",
       "60                    4.843353                     36.65   \n",
       "61                    6.282132                     30.75   \n",
       "62                    6.312584                    444.19   \n",
       "63                    4.031346                     40.66   \n",
       "\n",
       "    latest_loyalty_score_fs  avg_purchase_value_fs  avg_loyalty_score_fs  \n",
       "0                  4.481954             367.421667              3.985977  \n",
       "1                  2.698069             448.050000              2.698069  \n",
       "2                  6.958193             218.560000              7.664097  \n",
       "3                  6.958654             335.588333              7.609327  \n",
       "4                  4.413678             232.135000              3.961839  \n",
       "..                      ...                    ...                   ...  \n",
       "59                 6.561586              69.110000              7.162222  \n",
       "60                 4.843353             200.718333              4.601676  \n",
       "61                 6.282132             136.958333              6.726066  \n",
       "62                 6.312584             443.410000              6.621292  \n",
       "63                 4.031346             120.178333              3.450673  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 04:42:49 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file:                 <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                         </span>         ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 04:42:49 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file:                 \u001b]8;id=566015;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=558261;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                         \u001b[0m         ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m                                            \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 04:42:55 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Query <span style=\"color: #ffff00; text-decoration-color: #ffff00\">a8015e3f-d1c7-4929-8222-98d11e446ad7</span> is being executed.     <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6615\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6615</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 04:42:55 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Query \u001b[93ma8015e3f-d1c7-4929-8222-98d11e446ad7\u001b[0m is being executed.     \u001b]8;id=509921;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=257478;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6615\u001b\\\u001b[2m6615\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 04:43:01 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Query <span style=\"color: #ffff00; text-decoration-color: #ffff00\">a8015e3f-d1c7-4929-8222-98d11e446ad7</span> successfully executed. <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6624\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6624</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 04:43:01 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Query \u001b[93ma8015e3f-d1c7-4929-8222-98d11e446ad7\u001b[0m successfully executed. \u001b]8;id=645655;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=16711;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6624\u001b\\\u001b[2m6624\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "import boto3\n",
    "\n",
    "\n",
    "feature_group_name = \"customer_purchase_features\"\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\")\n",
    "featurestore_runtime = boto_session.client(service_name=\"sagemaker-featurestore-runtime\")\n",
    "\n",
    "\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")\n",
    "s3_bucket_name = feature_store_session.default_bucket()\n",
    "# Create a FeatureGroup object for the existing feature group\n",
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=feature_store_session)\n",
    "\n",
    "\n",
    "\n",
    "# Get the Athena query results as a dataframe\n",
    "query = feature_group.athena_query()\n",
    "customer_table = query.table_name\n",
    "query.run(query_string=f\"SELECT * FROM {customer_table}\", output_location=f\"s3://{s3_bucket_name}/feature-store/customer_features\")\n",
    "query.wait()\n",
    "train_df = query.as_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>latest_purchase_value</th>\n",
       "      <th>avg_purchase_value</th>\n",
       "      <th>avg_loyalty_score</th>\n",
       "      <th>latest_loyalty_score</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>2022-09-16T08:09:01.000000Z</td>\n",
       "      <td>167.33</td>\n",
       "      <td>354.890000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>5.246667</td>\n",
       "      <td>2024-12-28 19:32:24.894</td>\n",
       "      <td>2024-12-28 19:27:04.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2022-08-29T10:12:49.000000Z</td>\n",
       "      <td>476.20</td>\n",
       "      <td>360.220000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>5.972500</td>\n",
       "      <td>2024-12-28 19:32:24.879</td>\n",
       "      <td>2024-12-28 19:27:09.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>2024-12-28T16:34:16.061517Z</td>\n",
       "      <td>328.97</td>\n",
       "      <td>328.970000</td>\n",
       "      <td>2.639977</td>\n",
       "      <td>2.639977</td>\n",
       "      <td>2024-12-28 19:39:15.433</td>\n",
       "      <td>2024-12-28 19:34:16.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2022-06-24T17:25:48.000000Z</td>\n",
       "      <td>466.00</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>2024-12-28 19:32:24.914</td>\n",
       "      <td>2024-12-28 19:27:09.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>2022-09-11T12:48:34.000000Z</td>\n",
       "      <td>20.99</td>\n",
       "      <td>260.225000</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>2024-12-28 19:32:24.830</td>\n",
       "      <td>2024-12-28 19:27:17.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>66</td>\n",
       "      <td>2022-11-16T09:40:56.000000Z</td>\n",
       "      <td>278.41</td>\n",
       "      <td>263.106667</td>\n",
       "      <td>9.810000</td>\n",
       "      <td>6.263333</td>\n",
       "      <td>2024-12-28 19:32:24.866</td>\n",
       "      <td>2024-12-28 19:27:12.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>33</td>\n",
       "      <td>2022-06-08T20:12:20.000000Z</td>\n",
       "      <td>115.17</td>\n",
       "      <td>115.170000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>2024-12-28 19:32:24.833</td>\n",
       "      <td>2024-12-28 19:27:07.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>35</td>\n",
       "      <td>2024-12-28T16:33:52.196862Z</td>\n",
       "      <td>206.71</td>\n",
       "      <td>241.827500</td>\n",
       "      <td>2.880485</td>\n",
       "      <td>3.680970</td>\n",
       "      <td>2024-12-28 19:38:45.275</td>\n",
       "      <td>2024-12-28 19:33:52.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>82</td>\n",
       "      <td>2024-12-28T16:34:57.731470Z</td>\n",
       "      <td>252.89</td>\n",
       "      <td>272.420000</td>\n",
       "      <td>2.218766</td>\n",
       "      <td>3.237531</td>\n",
       "      <td>2024-12-28 19:38:45.275</td>\n",
       "      <td>2024-12-28 19:34:57.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>35</td>\n",
       "      <td>2024-12-28T16:35:09.609048Z</td>\n",
       "      <td>363.64</td>\n",
       "      <td>302.733750</td>\n",
       "      <td>3.507255</td>\n",
       "      <td>4.134025</td>\n",
       "      <td>2024-12-28 19:38:45.275</td>\n",
       "      <td>2024-12-28 19:35:09.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id           purchase_timestamp  latest_purchase_value  \\\n",
       "0             17  2022-09-16T08:09:01.000000Z                 167.33   \n",
       "1             50  2022-08-29T10:12:49.000000Z                 476.20   \n",
       "2             46  2024-12-28T16:34:16.061517Z                 328.97   \n",
       "3             48  2022-06-24T17:25:48.000000Z                 466.00   \n",
       "4             92  2022-09-11T12:48:34.000000Z                  20.99   \n",
       "..           ...                          ...                    ...   \n",
       "178           66  2022-11-16T09:40:56.000000Z                 278.41   \n",
       "179           33  2022-06-08T20:12:20.000000Z                 115.17   \n",
       "180           35  2024-12-28T16:33:52.196862Z                 206.71   \n",
       "181           82  2024-12-28T16:34:57.731470Z                 252.89   \n",
       "182           35  2024-12-28T16:35:09.609048Z                 363.64   \n",
       "\n",
       "     avg_purchase_value  avg_loyalty_score  latest_loyalty_score  \\\n",
       "0            354.890000           7.750000              5.246667   \n",
       "1            360.220000           9.950000              5.972500   \n",
       "2            328.970000           2.639977              2.639977   \n",
       "3            466.000000           5.480000              5.480000   \n",
       "4            260.225000           4.240000              4.090000   \n",
       "..                  ...                ...                   ...   \n",
       "178          263.106667           9.810000              6.263333   \n",
       "179          115.170000           4.750000              4.750000   \n",
       "180          241.827500           2.880485              3.680970   \n",
       "181          272.420000           2.218766              3.237531   \n",
       "182          302.733750           3.507255              4.134025   \n",
       "\n",
       "                  write_time      api_invocation_time  is_deleted  \n",
       "0    2024-12-28 19:32:24.894  2024-12-28 19:27:04.000       False  \n",
       "1    2024-12-28 19:32:24.879  2024-12-28 19:27:09.000       False  \n",
       "2    2024-12-28 19:39:15.433  2024-12-28 19:34:16.000       False  \n",
       "3    2024-12-28 19:32:24.914  2024-12-28 19:27:09.000       False  \n",
       "4    2024-12-28 19:32:24.830  2024-12-28 19:27:17.000       False  \n",
       "..                       ...                      ...         ...  \n",
       "178  2024-12-28 19:32:24.866  2024-12-28 19:27:12.000       False  \n",
       "179  2024-12-28 19:32:24.833  2024-12-28 19:27:07.000       False  \n",
       "180  2024-12-28 19:38:45.275  2024-12-28 19:33:52.000       False  \n",
       "181  2024-12-28 19:38:45.275  2024-12-28 19:34:57.000       False  \n",
       "182  2024-12-28 19:38:45.275  2024-12-28 19:35:09.000       False  \n",
       "\n",
       "[183 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_id': '44',\n",
       " 'purchase_timestamp': '2024-12-28T16:34:38.788282Z',\n",
       " 'latest_purchase_value': '405.51',\n",
       " 'avg_purchase_value': '243.85',\n",
       " 'avg_loyalty_score': '3.702876239800732',\n",
       " 'latest_loyalty_score': '4.2531591263570885'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core import utils\n",
    "customer_id = str(44)\n",
    "response = featurestore_runtime.get_record(\n",
    "            FeatureGroupName=\"customer_purchase_features\",\n",
    "            RecordIdentifierValueAsString=customer_id,\n",
    "        )\n",
    "\n",
    "record = response[\"Record\"]\n",
    "\n",
    "customer_features = {\n",
    "    \"customer_id\": utils.get_feature_value(record, \"customer_id\"),\n",
    "    \"purchase_timestamp\": utils.get_feature_value(record, \"purchase_timestamp\"),\n",
    "    \"latest_purchase_value\": utils.get_feature_value(\n",
    "        record, \"latest_purchase_value\"\n",
    "    ),\n",
    "    \"avg_purchase_value\": utils.get_feature_value(record, \"avg_purchase_value\"),\n",
    "    \"avg_loyalty_score\": utils.get_feature_value(record, \"avg_loyalty_score\"),\n",
    "    \"latest_loyalty_score\": utils.get_feature_value(\n",
    "        record, \"latest_loyalty_score\"\n",
    "    ),\n",
    "}\n",
    "customer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>latest_purchase_value</th>\n",
       "      <th>avg_purchase_value</th>\n",
       "      <th>avg_loyalty_score</th>\n",
       "      <th>latest_loyalty_score</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75</td>\n",
       "      <td>2024-12-28T13:34:50.309102Z</td>\n",
       "      <td>108.54</td>\n",
       "      <td>219.7900</td>\n",
       "      <td>3.831694</td>\n",
       "      <td>4.323389</td>\n",
       "      <td>2024-12-28 16:39:49.254</td>\n",
       "      <td>2024-12-28 16:34:50.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75</td>\n",
       "      <td>2024-12-28T13:36:02.414682Z</td>\n",
       "      <td>41.36</td>\n",
       "      <td>130.5750</td>\n",
       "      <td>4.184726</td>\n",
       "      <td>4.537759</td>\n",
       "      <td>2024-12-28 16:39:49.254</td>\n",
       "      <td>2024-12-28 16:36:02.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75</td>\n",
       "      <td>2024-12-28T13:36:03.727881Z</td>\n",
       "      <td>464.28</td>\n",
       "      <td>297.4275</td>\n",
       "      <td>4.501495</td>\n",
       "      <td>4.818263</td>\n",
       "      <td>2024-12-28 16:39:49.254</td>\n",
       "      <td>2024-12-28 16:36:03.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>75</td>\n",
       "      <td>2022-11-08T02:13:37.000000Z</td>\n",
       "      <td>331.04</td>\n",
       "      <td>331.0400</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>2024-12-28 16:33:08.652</td>\n",
       "      <td>2024-12-28 16:27:35.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id           purchase_timestamp  latest_purchase_value  \\\n",
       "11           75  2024-12-28T13:34:50.309102Z                 108.54   \n",
       "13           75  2024-12-28T13:36:02.414682Z                  41.36   \n",
       "14           75  2024-12-28T13:36:03.727881Z                 464.28   \n",
       "57           75  2022-11-08T02:13:37.000000Z                 331.04   \n",
       "\n",
       "    avg_purchase_value  avg_loyalty_score  latest_loyalty_score  \\\n",
       "11            219.7900           3.831694              4.323389   \n",
       "13            130.5750           4.184726              4.537759   \n",
       "14            297.4275           4.501495              4.818263   \n",
       "57            331.0400           3.340000              3.340000   \n",
       "\n",
       "                 write_time      api_invocation_time  is_deleted  \n",
       "11  2024-12-28 16:39:49.254  2024-12-28 16:34:50.000       False  \n",
       "13  2024-12-28 16:39:49.254  2024-12-28 16:36:02.000       False  \n",
       "14  2024-12-28 16:39:49.254  2024-12-28 16:36:03.000       False  \n",
       "57  2024-12-28 16:33:08.652  2024-12-28 16:27:35.000       False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"customer_id\"]==75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>loyalty_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>2022-07-29 10:31:41</td>\n",
       "      <td>442.01</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2022-06-26 19:55:11</td>\n",
       "      <td>284.25</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-05-13 22:06:27</td>\n",
       "      <td>61.07</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>2022-10-23 02:07:22</td>\n",
       "      <td>465.32</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>2022-03-20 00:13:33</td>\n",
       "      <td>224.45</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-29 16:35:12</td>\n",
       "      <td>40.66</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>43</td>\n",
       "      <td>2022-06-21 03:57:59</td>\n",
       "      <td>204.85</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>39</td>\n",
       "      <td>2022-04-11 17:14:50</td>\n",
       "      <td>222.57</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>93</td>\n",
       "      <td>2022-11-01 20:34:21</td>\n",
       "      <td>17.05</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>75</td>\n",
       "      <td>2022-05-31 10:57:56</td>\n",
       "      <td>108.54</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id   purchase_timestamp  purchase_value  loyalty_score\n",
       "0            80  2022-07-29 10:31:41          442.01           2.09\n",
       "1            20  2022-06-26 19:55:11          284.25           1.95\n",
       "2            13  2022-05-13 22:06:27           61.07           4.46\n",
       "3            32  2022-10-23 02:07:22          465.32           4.65\n",
       "4            63  2022-03-20 00:13:33          224.45           3.11\n",
       "..          ...                  ...             ...            ...\n",
       "87          100  2022-01-29 16:35:12           40.66           2.89\n",
       "88           43  2022-06-21 03:57:59          204.85           7.86\n",
       "89           39  2022-04-11 17:14:50          222.57           9.19\n",
       "90           93  2022-11-01 20:34:21           17.05           7.88\n",
       "91           75  2022-05-31 10:57:56          108.54           6.31\n",
       "\n",
       "[92 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dd =pd.read_csv(\"data/inference_data.csv\")\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id\n",
       "75    3\n",
       "44    3\n",
       "69    3\n",
       "39    2\n",
       "28    2\n",
       "     ..\n",
       "79    1\n",
       "95    1\n",
       "25    1\n",
       "37    1\n",
       "43    1\n",
       "Name: count, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>loyalty_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>16</td>\n",
       "      <td>2022-06-11 03:17:36</td>\n",
       "      <td>69.30</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>16</td>\n",
       "      <td>2022-04-20 11:47:32</td>\n",
       "      <td>413.66</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id   purchase_timestamp  purchase_value  loyalty_score\n",
       "76           16  2022-06-11 03:17:36           69.30           4.77\n",
       "82           16  2022-04-20 11:47:32          413.66           9.60"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[dd[\"customer_id\"]==16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Test historical data storage and retrieval:\n",
    "## All the customer id in the test data must be in the feature store\n",
    "## All transactions made by each customer must be in the feature store\n",
    "\n",
    "# 2- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 03:22:38 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file:                 <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                         </span>         ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 03:22:38 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file:                 \u001b]8;id=849983;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=65064;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                         \u001b[0m         ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m                                            \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected customers for testing: [20, 65, 44, 39, 69, 28, 15, 86]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 03:22:43 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Query <span style=\"color: #ffff00; text-decoration-color: #ffff00\">85ad9ca4-0ea5-482f-8ca4-006772cdab29</span> is being executed.     <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6615\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6615</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 03:22:43 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Query \u001b[93m85ad9ca4-0ea5-482f-8ca4-006772cdab29\u001b[0m is being executed.     \u001b]8;id=896754;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=816441;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6615\u001b\\\u001b[2m6615\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/28/2024 03:22:49 PM] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Query <span style=\"color: #ffff00; text-decoration-color: #ffff00\">85ad9ca4-0ea5-482f-8ca4-006772cdab29</span> successfully executed. <a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6624\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6624</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/28/2024 03:22:49 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Query \u001b[93m85ad9ca4-0ea5-482f-8ca4-006772cdab29\u001b[0m successfully executed. \u001b]8;id=122297;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=105994;file:///home/hicham/Desktop/personal/Pipedrive/.venv/lib/python3.9/site-packages/sagemaker/session.py#6624\u001b\\\u001b[2m6624\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All selected customers have at least 2 records in the offline store\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "\n",
    "def get_offline_store_data(feature_group):\n",
    "    \"\"\"Fetch all data from offline feature store\"\"\"\n",
    "    query = feature_group.athena_query()\n",
    "    customer_table = query.table_name\n",
    "    query.run(\n",
    "        query_string=f\"SELECT * FROM {customer_table}\", \n",
    "        output_location=f\"s3://{feature_group.sagemaker_session.default_bucket()}/feature-store/test_queries\"\n",
    "    )\n",
    "    query.wait()\n",
    "    return query.as_dataframe()\n",
    "\n",
    "def get_random_customers_with_multiple_records(csv_path, min_records=2, num_customers=8):\n",
    "    \"\"\"Find random customers that appear multiple times in the CSV\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    customer_counts = df['customer_id'].value_counts()\n",
    "    eligible_customers = customer_counts[customer_counts >= min_records].index.tolist()\n",
    "    \n",
    "    if len(eligible_customers) < num_customers:\n",
    "        raise ValueError(f\"Not enough customers with {min_records} or more records\")\n",
    "    \n",
    "    return np.random.choice(eligible_customers, num_customers, replace=False).tolist()\n",
    "\n",
    "def check_customer_records(customer_id, offline_df):\n",
    "    \"\"\"Check if a customer has enough records in the offline store\"\"\"\n",
    "    customer_records = offline_df[offline_df['customer_id'] == customer_id]\n",
    "    return len(customer_records) >= 2\n",
    "\n",
    "# Setup Feature Store connection\n",
    "feature_group_name = \"customer_purchase_features\"\n",
    "boto_session = boto3.Session()\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\")\n",
    "featurestore_runtime = boto_session.client(service_name=\"sagemaker-featurestore-runtime\")\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")\n",
    "\n",
    "# Create Feature Group object\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, \n",
    "    sagemaker_session=feature_store_session\n",
    ")\n",
    "\n",
    "# Test data consistency\n",
    "def test_feature_store_data():\n",
    "    # Get random customers from CSV\n",
    "    csv_path = \"data/inference_data.csv\"  # Replace with your CSV path\n",
    "    try:\n",
    "        test_customers = get_random_customers_with_multiple_records(csv_path)\n",
    "        print(f\"Selected customers for testing: {test_customers}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Get offline store data\n",
    "    offline_df = get_offline_store_data(feature_group)\n",
    "    \n",
    "    # Check each customer's records\n",
    "    failed_customers = []\n",
    "    for customer_id in test_customers:\n",
    "        if not check_customer_records(customer_id, offline_df):\n",
    "            failed_customers.append(customer_id)\n",
    "    \n",
    "    # Print results\n",
    "    if failed_customers:\n",
    "        print(f\"The following customers have fewer than 2 records: {failed_customers}\")\n",
    "    else:\n",
    "        print(\"All selected customers have at least 2 records in the offline store\")\n",
    "\n",
    "    return len(failed_customers) == 0\n",
    "\n",
    "\n",
    "success = test_feature_store_data()\n",
    "print(f\"Test {'passed' if success else 'failed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing customers: [63, 16, 88, 15, 9, 86, 56, 44, 65, 13, 9, 18]\n",
      "\n",
      "Customer: 63\n",
      "CSV Purchase Value: 22.34\n",
      "Online Purchase Value: 22.34\n",
      "CSV Timestamp: 2022-04-11 03:17:48\n",
      "Online Timestamp: 2024-12-28T13:34:29.238626Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 16\n",
      "CSV Purchase Value: 69.3\n",
      "Online Purchase Value: 69.3\n",
      "CSV Timestamp: 2022-06-11 03:17:36\n",
      "Online Timestamp: 2024-12-28T13:34:52.254019Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 88\n",
      "CSV Purchase Value: 432.14\n",
      "Online Purchase Value: 432.14\n",
      "CSV Timestamp: 2022-11-10 07:44:58\n",
      "Online Timestamp: 2024-12-28T13:35:46.681431Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 15\n",
      "CSV Purchase Value: 52.68\n",
      "Online Purchase Value: 52.68\n",
      "CSV Timestamp: 2022-11-07 08:08:23\n",
      "Online Timestamp: 2024-12-28T13:35:45.806961Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 9\n",
      "CSV Purchase Value: 459.86\n",
      "Online Purchase Value: 459.86\n",
      "CSV Timestamp: 2022-10-09 07:23:13\n",
      "Online Timestamp: 2024-12-28T13:36:05.058671Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 86\n",
      "CSV Purchase Value: 385.59\n",
      "Online Purchase Value: 385.59\n",
      "CSV Timestamp: 2022-07-27 15:24:35\n",
      "Online Timestamp: 2024-12-28T13:35:13.552902Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 56\n",
      "CSV Purchase Value: 342.98\n",
      "Online Purchase Value: 342.98\n",
      "CSV Timestamp: 2022-07-13 16:21:33\n",
      "Online Timestamp: 2024-12-28T13:35:08.536152Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 44\n",
      "CSV Purchase Value: 405.51\n",
      "Online Purchase Value: 405.51\n",
      "CSV Timestamp: 2022-07-01 09:58:46\n",
      "Online Timestamp: 2024-12-28T13:35:04.849127Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 65\n",
      "CSV Purchase Value: 103.8\n",
      "Online Purchase Value: 103.8\n",
      "CSV Timestamp: 2022-04-24 11:52:10\n",
      "Online Timestamp: 2024-12-28T13:34:37.304097Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 13\n",
      "CSV Purchase Value: 299.93\n",
      "Online Purchase Value: 299.93\n",
      "CSV Timestamp: 2022-08-21 20:50:37\n",
      "Online Timestamp: 2024-12-28T13:35:19.492543Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 9\n",
      "CSV Purchase Value: 459.86\n",
      "Online Purchase Value: 459.86\n",
      "CSV Timestamp: 2022-10-09 07:23:13\n",
      "Online Timestamp: 2024-12-28T13:36:05.058671Z\n",
      "✅ Values match!\n",
      "\n",
      "Customer: 18\n",
      "CSV Purchase Value: 229.94\n",
      "Online Purchase Value: 229.94\n",
      "CSV Timestamp: 2022-03-23 08:11:34\n",
      "Online Timestamp: 2024-12-28T13:36:01.372615Z\n",
      "✅ Values match!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from core import utils\n",
    "\n",
    "def get_random_customers(csv_path, num_customers=10):\n",
    "    \"\"\"Get random customers from CSV that appear more than once\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    customer_counts = df['customer_id'].value_counts()\n",
    "    multiple_records = customer_counts[customer_counts > 1].index.tolist()\n",
    "    return np.random.choice(multiple_records, num_customers, replace=False).tolist()\n",
    "\n",
    "def test_online_vs_csv():\n",
    "    # Get random customers from CSV\n",
    "    csv_path = \"data/inference_data.csv\"  # Update with your CSV path\n",
    "    test_customers = get_random_customers(csv_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    test_customers.append(9)\n",
    "    test_customers.append(18)\n",
    "    print(\"Testing customers:\", test_customers)\n",
    "    \n",
    "    for customer_id in test_customers:\n",
    "        # Get latest CSV record\n",
    "        customer_df = df[df['customer_id'] == customer_id]\n",
    "        latest_csv = customer_df.sort_values('purchase_timestamp', ascending=False).iloc[0]\n",
    "        \n",
    "        # Get online store record\n",
    "        response = featurestore_runtime.get_record(\n",
    "            FeatureGroupName=\"customer_purchase_features\",\n",
    "            RecordIdentifierValueAsString=str(customer_id),\n",
    "        )\n",
    "        record = response[\"Record\"]\n",
    "        online_features = {\n",
    "            \"customer_id\": utils.get_feature_value(record, \"customer_id\"),\n",
    "            \"purchase_timestamp\": utils.get_feature_value(record, \"purchase_timestamp\"),\n",
    "            \"latest_purchase_value\": float(utils.get_feature_value(record, \"latest_purchase_value\")),\n",
    "        }\n",
    "        \n",
    "        # Compare values\n",
    "        csv_purchase = float(latest_csv['purchase_value'])\n",
    "        online_purchase = online_features['latest_purchase_value']\n",
    "        \n",
    "        print(f\"\\nCustomer: {customer_id}\")\n",
    "        print(f\"CSV Purchase Value: {csv_purchase}\")\n",
    "        print(f\"Online Purchase Value: {online_purchase}\")\n",
    "        print(f\"CSV Timestamp: {latest_csv['purchase_timestamp']}\")\n",
    "        print(f\"Online Timestamp: {online_features['purchase_timestamp']}\")\n",
    "        \n",
    "        if abs(csv_purchase - online_purchase) > 0.0001:\n",
    "            print(\"❌ Values don't match!\")\n",
    "        else:\n",
    "            print(\"✅ Values match!\")\n",
    "\n",
    "\n",
    "test_online_vs_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
